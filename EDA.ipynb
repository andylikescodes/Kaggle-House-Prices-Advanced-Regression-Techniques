{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Procedure - Regression\n",
    "\n",
    "## Basic Understanding of the Dataset\n",
    "\n",
    "1. Is it a classification problem or a regression problem?\n",
    "2. How many records in the dataset?\n",
    "3. How many variables in the dataset?\n",
    "4. What is the output variable?\n",
    "5. What are the quantitive variables?\n",
    "6. What are the qualitative variables?\n",
    "7. Is there any null values?\n",
    "8. Is the data clean? (Each variable has the same data type, etc.)\n",
    "\n",
    "## Data Cleaning and Preprocessing\n",
    "\n",
    "1. Fill in missing values with mode, mean, or 'None'.\n",
    "2. Transform data types.\n",
    "3. Plot pairwise numerical records.\n",
    "4. Output a clean dataset.\n",
    "\n",
    "## Statistical Analysis\n",
    "\n",
    "### Look for Outliers\n",
    "\n",
    "1. Pairwise graphs\n",
    "\n",
    "### For Categorical variables:\n",
    "\n",
    "1. Plot boxplot to see relationships.\n",
    "2. List pvals from lowest to highest in Anova analysis for categories in each variable.\n",
    "3. Transform categorical variables into sequential data ordering (based on mean)\n",
    "\n",
    "### Num and Ordered Transformed Cat variables together:\n",
    "\n",
    "1. Plot pair-wise graph\n",
    "2. List variables with linear relationship with the output variable.\n",
    "3. List variables with quadratic relationship with the output variable.\n",
    "4. List variables with other non-linear relationship with the output variable.\n",
    "5. Plot correlation matrix.\n",
    "6. List variables with high correlation with the output variable.\n",
    "7. List all the pairs of variables with high colinearlity.\n",
    "8. Plot Spearman correlation to inspect non-linear relationship (monotonic increasing or decreasing)\n",
    "\n",
    "## Feature Engineering and Model Selection\n",
    "\n",
    "### Training Set and Testing Set\n",
    "\n",
    "1. Split the dataset into training and testing set.\n",
    "\n",
    "### Linear Models\n",
    "\n",
    "1. List all variables that have high correlation with the output variable.\n",
    "2. Keep one of the variables in the pairs that have high colinearities.\n",
    "\n",
    "#### a. Lasso\n",
    "1. Select best alpha from GridSearchCV, alpha=[10\\**i for i in np.linspace(0.001, 10, 100)].\n",
    "2. Record best alpha.\n",
    "3. Record best cv error.\n",
    "4. Refit to the training set using the best alpha.\n",
    "5. Predict on testing data.\n",
    "6. Record testing error.\n",
    "\n",
    "#### b. Ridge\n",
    "1. Select best alpha from GridSearchCV, alpha=[10\\**i for i in np.linspace(0.001, 10, 100)].\n",
    "2. Record best alpha.\n",
    "3. Record best cv error.\n",
    "4. Refit to the training set using the best alpha.\n",
    "5. Predict on testing data.\n",
    "6. Record testing error.\n",
    "\n",
    "#### c. PCA\n",
    "1. PCA transformation.\n",
    "2. CV score for each subset of PCA.\n",
    "3. Record the best cv error.\n",
    "3. Fit the full training set on the selected subset of principle components.\n",
    "4. Predict on testing data.\n",
    "5. Record testing error.\n",
    "\n",
    "#### d. Elastic Net (look into it later)\n",
    "\n",
    "#### e. Non-negative Garrot (look into it later)\n",
    "\n",
    "### Polynomial Regression (2nd order)\n",
    "\n",
    "1. Add variables that have high correlation with the output variable to the model.\n",
    "2. Add quadratic terms with variables that have \n",
    "3. Get rid of variables with high colinearlities. \n",
    "4. Lasso (or Ridge), Select best alpha from GridSearchCV, alpha=[10\\**i for i in np.linspace(0.001, 10, 100)].\n",
    "5. Record best alpha.\n",
    "6. Record best cv error.\n",
    "7. Refit to the training set using the best alpha.\n",
    "8. Predict on testing data.\n",
    "9. Record testing error.\n",
    "\n",
    "### Regression Spline\n",
    "\n",
    "1. Add variables that have high correlation with the output variable to the model.\n",
    "2. Add quadratic terms with variables that have \n",
    "3. Add spline terms with appropriate knots (degrees of freedom)\n",
    "3. Get rid of variables with high colinearlities. \n",
    "4. sklearn.Linear_models.Lasso (or Ridge), Select best alpha from GridSearchCV, alpha=[10\\**i for i in np.linspace(0.001, 10, 100)].\n",
    "5. Record best alpha.\n",
    "6. Record best cv error.\n",
    "7. Refit to the training set using the best alpha.\n",
    "8. Predict on testing data.\n",
    "9. Record testing error.\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "1. Use the same variables crafted for the linear models\n",
    "2. sklearn.ensemble.RandomForest, GridSearchCV, params = {'n_estimators': [100, 200, 300, 400, 500], 'max_features'=[0.3, 0.5, 1.0], 'min_samples_split': np.arange(1,10,2)}\n",
    "3. Record the best params.\n",
    "4. Record the best cv scores.\n",
    "5. Refit the tree using the whole dataset.\n",
    "6. Predict on testing data.\n",
    "7. Record testing error.\n",
    "\n",
    "### Gradient Boosting\n",
    "\n",
    "1. 1. Use the same variables crafted for the linear models\n",
    "2. sklearn.ensemble.GradientBoostingRegressor, GridSearchCV, params = {'n_estimators': [100, 200, 300, 400, 500], 'max_depth'=[1,2,3], 'min_samples_split': np.arange(1,10,2)}\n",
    "3. Record the best params.\n",
    "4. Record the best cv scores.\n",
    "5. Refit the tree using the whole dataset.\n",
    "6. Predict on testing data.\n",
    "7. Record testing error.\n",
    "\n",
    "### XGBoost\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
